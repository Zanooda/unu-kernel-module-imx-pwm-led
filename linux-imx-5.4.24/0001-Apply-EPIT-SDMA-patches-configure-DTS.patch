From 00ba238ac9db3acb2aa8fde895ac4b9f65ce75f8 Mon Sep 17 00:00:00 2001
From: Geoff Phillips <geoff@unumotors.com>
Date: Tue, 5 May 2020 17:15:59 +0200
Subject: [PATCH] Apply EPIT, SDMA patches, configure DTS

Remove redundant DTS file
Tidy up DTS file, configure EPIT and PWMs
---
 arch/arm/mach-imx/Kconfig                  |  22 +
 arch/arm/mach-imx/Makefile                 |   2 +
 arch/arm/mach-imx/epit_api.c               | 333 +++++++++++++++
 drivers/dma/imx-sdma.c                     | 453 ++++++++++++++-------
 include/linux/platform_data/dma-imx-sdma.h | 319 ++++++++++++++-
 include/linux/platform_data/epit-imx.h     | 141 +++++++
 6 files changed, 1130 insertions(+), 140 deletions(-)
 create mode 100644 arch/arm/mach-imx/epit_api.c
 create mode 100644 include/linux/platform_data/epit-imx.h

diff --git a/arch/arm/mach-imx/Kconfig b/arch/arm/mach-imx/Kconfig
index cb6340b2eb33..763ef90d4289 100644
--- a/arch/arm/mach-imx/Kconfig
+++ b/arch/arm/mach-imx/Kconfig
@@ -33,6 +33,27 @@ config MXC_DEBUG_BOARD
 	  data/address de-multiplexing and decode, signal level shift,
 	  interrupt control and various board functions.
 
+config HAVE_EPIT
+	bool
+
+config MXC_USE_EPIT
+	bool "Use EPIT instead of GPT"
+	depends on HAVE_EPIT
+	help
+	  Use EPIT as the system timer on systems that have it. Normally you
+	  don't have a reason to do so as the EPIT has the same features and
+	  uses the same clocks as the GPT. Anyway, on some systems the GPT
+	  may be in use for other purposes.
+
+config MXC_EPIT_API
+	bool "Allow EPIT1/EPIT2 to be used in kernel modules"
+	depends on !MXC_USE_EPIT
+	help
+		Exposes an API for EPIT1/EPIT2.
+
+config HAVE_IMX_RNG
+       bool
+
 config HAVE_IMX_ANATOP
 	bool
 
@@ -94,6 +115,7 @@ config SOC_IMX31
 config SOC_IMX35
 	bool
 	select ARCH_MXC_IOMUX_V3
+	select HAVE_EPIT
 	select MXC_AVIC
 	select PINCTRL_IMX35
 
diff --git a/arch/arm/mach-imx/Makefile b/arch/arm/mach-imx/Makefile
index 98a07af52779..dd544fc00c67 100644
--- a/arch/arm/mach-imx/Makefile
+++ b/arch/arm/mach-imx/Makefile
@@ -20,6 +20,8 @@ obj-$(CONFIG_ARCH_MXC_IOMUX_V3) += iomux-v3.o
 obj-$(CONFIG_MXC_TZIC) += tzic.o
 obj-$(CONFIG_MXC_AVIC) += avic.o
 
+obj-$(CONFIG_MXC_USE_EPIT) += epit.o
+obj-$(CONFIG_MXC_EPIT_API) += epit_api.o
 obj-$(CONFIG_MXC_DEBUG_BOARD) += 3ds_debugboard.o
 
 ifeq ($(CONFIG_CPU_IDLE),y)
diff --git a/arch/arm/mach-imx/epit_api.c b/arch/arm/mach-imx/epit_api.c
new file mode 100644
index 000000000000..8106575dde29
--- /dev/null
+++ b/arch/arm/mach-imx/epit_api.c
@@ -0,0 +1,333 @@
+/**
+ * Low-level i.MX6 EPIT API.
+ * Copyright (C) 2018 Scott Wiederhold <s.e.wiederhold@gmail.com>
+ * Portions Copyright (C) 2015-2018 Glowforge, Inc. <opensource@glowforge.com>
+ */
+
+#include <linux/platform_data/epit-imx.h>
+#include <linux/clk.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/regmap.h>
+#include <linux/mfd/syscon.h>
+#include <linux/mfd/syscon/imx6q-iomuxc-gpr.h>
+
+/* Register offsets */
+#define EPITCR              0x00  /* control register */
+#define EPITSR              0x04  /* status register */
+#define EPITLR              0x08  /* load register */
+#define EPITCMPR            0x0c  /* compare register */
+#define EPITCNR             0x10  /* counter register */
+
+/* Control register bits */
+#define EPITCR_EN                 (1 << 0)
+#define EPITCR_ENMOD              (1 << 1)
+#define EPITCR_OCIEN              (1 << 2)
+#define EPITCR_RLD                (1 << 3)
+#define EPITCR_PRESC(x)           (((x) & 0xfff) << 4)
+#define EPITCR_SWR                (1 << 16)
+#define EPITCR_IOVW               (1 << 17)
+#define EPITCR_DBGEN              (1 << 18)
+#define EPITCR_WAITEN             (1 << 19)
+#define EPITCR_RES                (1 << 20)
+#define EPITCR_STOPEN             (1 << 21)
+#define EPITCR_OM_DISCON          (0 << 22)
+#define EPITCR_OM_TOGGLE          (1 << 22)
+#define EPITCR_OM_CLEAR           (2 << 22)
+#define EPITCR_OM_SET             (3 << 22)
+#define EPITCR_CLKSRC_OFF         (0 << 24)
+#define EPITCR_CLKSRC_PERIPHERAL  (1 << 24)
+#define EPITCR_CLKSRC_REF_HIGH    (2 << 24)
+#define EPITCR_CLKSRC_REF_LOW     (3 << 24)
+
+/* Status register bits */
+#define EPITSR_OCIF               (1 << 0)
+
+struct epit {
+	void __iomem *base;
+	struct clk *clk;
+	unsigned long rate;
+	u32 base_phys;
+	int irq;
+	int sdma_event;
+	epit_cb callback;
+	void *cb_arg;
+};
+
+static irqreturn_t epit_irq_handler_freerunning(int irq, void *dev_id)
+{
+	struct epit *epit = dev_id;
+	/* clear previous interrupt status */
+	__raw_writel(EPITSR_OCIF, epit->base+EPITSR);
+	/* call the callback */
+	epit->callback(epit->cb_arg);
+	return IRQ_HANDLED;
+}
+
+static irqreturn_t epit_irq_handler_oneshot(int irq, void *dev_id)
+{
+	struct epit *epit = dev_id;
+	u32 val;
+
+	/* clear previous interrupt status */
+	__raw_writel(EPITSR_OCIF, epit->base+EPITSR);
+	/* stop counting */
+	val = __raw_readl(epit->base+EPITCR);
+	val &= ~EPITCR_EN;
+	__raw_writel(val, epit->base+EPITCR);
+	/* call the callback */
+	epit->callback(epit->cb_arg);
+	return IRQ_HANDLED;
+}
+
+static int epit_init(struct epit *epit, epit_cb callback,
+	void *cb_arg, irqreturn_t (*irq_handler)(int, void *))
+{
+	u32 val;
+	int ret = 0;
+	/* zero out control register */
+	__raw_writel(0, epit->base+EPITCR);
+	/* clear previous interrupt status */
+	__raw_writel(EPITSR_OCIF, epit->base+EPITSR);
+	/* set counter reset value */
+	__raw_writel(0, epit->base+EPITLR);
+	/* zero out compare register */
+	__raw_writel(0, epit->base+EPITCMPR);
+	/* set mode and clock source; enable interrupt */
+	/* peripheral clock is 66MHz */
+	val = EPITCR_CLKSRC_REF_HIGH|EPITCR_WAITEN|EPITCR_RLD|EPITCR_OCIEN
+		|EPITCR_ENMOD;
+	__raw_writel(val, epit->base+EPITCR);
+	/* set up callback, register an IRQ handler if necessary */
+	epit->callback = callback;
+	epit->cb_arg = cb_arg;
+	if (callback) {
+		ret = request_irq(epit->irq, irq_handler,
+			IRQF_TIMER|IRQF_IRQPOLL, "epit", epit);
+		if (ret) { epit->callback = NULL; }
+	}
+	return ret;
+}
+
+int epit_init_freerunning(struct epit *epit, epit_cb callback, void *cb_arg)
+{
+	return epit_init(epit, callback, cb_arg, epit_irq_handler_freerunning);
+}
+EXPORT_SYMBOL(epit_init_freerunning);
+
+int epit_init_oneshot(struct epit *epit, epit_cb callback, void *cb_arg)
+{
+	return epit_init(epit, callback, cb_arg, epit_irq_handler_oneshot);
+}
+EXPORT_SYMBOL(epit_init_oneshot);
+
+u32 epit_hz_to_divisor(struct epit *epit, u32 hz)
+{
+	return (hz) ? epit->rate/hz : 0;
+}
+EXPORT_SYMBOL(epit_hz_to_divisor);
+
+void epit_start(struct epit *epit, u32 divisor)
+{
+	u32 val;
+	/* clear previous interrupt status */
+	__raw_writel(EPITSR_OCIF, epit->base+EPITSR);
+	/* set divisor */
+	__raw_writel(divisor, epit->base+EPITLR);
+	/* start counting */
+	val = __raw_readl(epit->base+EPITCR);
+	val |= EPITCR_EN;
+	__raw_writel(val, epit->base+EPITCR);
+}
+EXPORT_SYMBOL(epit_start);
+
+void epit_start_hz(struct epit *epit, u32 hz)
+{
+	epit_start(epit, epit_hz_to_divisor(epit, hz));
+}
+EXPORT_SYMBOL(epit_start_hz);
+
+void epit_stop(struct epit *epit)
+{
+	/* stop counting */
+	u32 val = __raw_readl(epit->base+EPITCR);
+	val &= ~EPITCR_EN;
+	__raw_writel(val, epit->base+EPITCR);
+}
+EXPORT_SYMBOL(epit_stop);
+
+void epit_set_divisor(struct epit *epit, u32 divisor)
+{
+	__raw_writel(divisor, epit->base+EPITLR);
+}
+EXPORT_SYMBOL(epit_set_divisor);
+
+void epit_set_hz(struct epit *epit, u32 hz)
+{
+	epit_set_divisor(epit, epit_hz_to_divisor(epit, hz));
+}
+EXPORT_SYMBOL(epit_set_hz);
+
+u32 epit_count(struct epit *epit)
+{
+	return __raw_readl(epit->base+EPITCNR);
+}
+EXPORT_SYMBOL(epit_count);
+
+int epit_is_running(struct epit *epit)
+{
+	return (__raw_readl(epit->base+EPITCR) & EPITCR_EN) != 0;
+}
+EXPORT_SYMBOL(epit_is_running);
+
+int epit_irq(struct epit *epit)
+{
+	return epit->irq;
+}
+EXPORT_SYMBOL(epit_irq);
+
+int epit_sdma_event(struct epit *epit)
+{
+	return epit->sdma_event;
+}
+EXPORT_SYMBOL(epit_sdma_event);
+
+u32 epit_status_register_address(struct epit *epit)
+{
+	return epit->base_phys+EPITSR;
+}
+EXPORT_SYMBOL(epit_status_register_address);
+
+struct epit *epit_get(struct device_node *np)
+{
+	struct platform_device *pdev = of_find_device_by_node(np);
+	struct epit *epit = NULL;
+	if (!pdev) { return NULL; }
+	epit = platform_get_drvdata(pdev);
+	return epit;
+}
+EXPORT_SYMBOL(epit_get);
+
+static ssize_t status_show(struct device *dev, struct device_attribute *attr, char *buf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct epit *epit = platform_get_drvdata(pdev);
+  	return scnprintf(buf, PAGE_SIZE,
+		"CR=%04x SR=%04x LR=%04x CMPR=%04x CNR=%04x\n",
+		__raw_readl(epit->base+EPITCR),
+		__raw_readl(epit->base+EPITSR),
+		__raw_readl(epit->base+EPITLR),
+		__raw_readl(epit->base+EPITCMPR),
+		__raw_readl(epit->base+EPITCNR)
+	);
+}
+static DEVICE_ATTR(status, S_IRUSR, status_show, NULL);
+
+static int epit_probe(struct platform_device *pdev)
+{
+	struct epit *epit;
+	struct device_node *np = pdev->dev.of_node;
+
+	/* allocate driver data */
+	epit = devm_kzalloc(&pdev->dev, sizeof(*epit), GFP_KERNEL);
+	if (!epit) {
+		return -ENOMEM;
+	}
+	platform_set_drvdata(pdev, epit);
+
+	/* map registers */
+	epit->base = devm_ioremap_resource(&pdev->dev, pdev->resource);
+	if (unlikely(IS_ERR(epit->base))) {
+		return PTR_ERR(epit->base);
+	}
+	epit->base_phys = pdev->resource->start;
+
+	/* get irq */
+	epit->irq = platform_get_irq(pdev, 0);
+	if (unlikely(epit->irq < 0)) {
+		return -EINVAL;
+	}
+
+	/* get clock */
+	epit->clk = of_clk_get(np, 0);
+	if (IS_ERR(epit->clk)) {
+		return -EINVAL;
+	}
+	clk_prepare_enable(epit->clk);
+
+	/* get SDMA event */
+	if (unlikely(of_property_read_u32(np, "sdma-event",
+		&epit->sdma_event) != 0)) {
+		epit->sdma_event = -1;
+	}
+	/* event may need to be explicitly selected */
+	if (of_find_property(np, "sdma-event-select", NULL)) {
+		struct of_phandle_args args;
+		if (of_parse_phandle_with_fixed_args(np,
+		  "sdma-event-select", 3, 0, &args) == 0) {
+			struct regmap *gpr = syscon_node_to_regmap(args.np);
+			if (!IS_ERR(gpr)) {
+				regmap_update_bits(gpr,
+					args.args[0],
+					args.args[1],
+					args.args[2]);
+			} else {
+				dev_err(&pdev->dev, "regmap not found, "
+					"cannot enable SDMA event\n");
+			}
+			of_node_put(args.np);
+		} else {
+			dev_err(&pdev->dev, "invalid sdma-event-select params");
+		}
+	}
+
+	/* zero out control register and clear previous interrupt status */
+	__raw_writel(0, epit->base+EPITCR);
+	__raw_writel(EPITSR_OCIF, epit->base+EPITSR);
+
+	epit->rate = clk_get_rate(epit->clk);
+	dev_info(&pdev->dev, "irq=%d, rate=%ld, sdma_event=%d\n",
+		epit->irq, epit->rate, epit->sdma_event);
+
+	/* Create SYSFS entry for debugging purposes */
+	device_create_file(&pdev->dev, &dev_attr_status);
+
+	return 0;
+}
+
+static int epit_remove(struct platform_device *pdev)
+{
+	/* all resources released by devm */
+	struct epit *epit = platform_get_drvdata(pdev);
+	epit_stop(epit);
+	if (epit->callback) {
+		free_irq(epit->irq, epit);
+	}
+	clk_disable_unprepare(epit->clk);
+	return 0;
+}
+
+static const struct of_device_id epit_dt_ids[] = {
+	{ .compatible = "fsl,imx6ul-epit" },
+	{ /* sentinel */ }
+};
+MODULE_DEVICE_TABLE(of, epit_dt_ids);
+
+static struct platform_driver epit_driver = {
+	.driver = {
+		.name = "epit",
+		.owner = THIS_MODULE,
+		.of_match_table = epit_dt_ids
+	},
+	.probe = epit_probe,
+	.remove = epit_remove
+};
+module_platform_driver(epit_driver);
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Scott Wiederhold <s.e.wiederhold@gmail.com>");
diff --git a/drivers/dma/imx-sdma.c b/drivers/dma/imx-sdma.c
index 09ae4282ad56..182be7bfd46d 100644
--- a/drivers/dma/imx-sdma.c
+++ b/drivers/dma/imx-sdma.c
@@ -26,6 +26,7 @@
 #include <linux/device.h>
 #include <linux/genalloc.h>
 #include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
 #include <linux/firmware.h>
 #include <linux/slab.h>
 #include <linux/platform_device.h>
@@ -194,139 +195,6 @@
 #define SDMA_WATERMARK_LEVEL_SW_DONE	BIT(23)
 #define SDMA_WATERMARK_LEVEL_SW_DONE_SEL_OFF 24
 
-/*
- * Mode/Count of data node descriptors - IPCv2
- */
-struct sdma_mode_count {
-#define SDMA_BD_MAX_CNT	0xffff
-	u32 count   : 16; /* size of the buffer pointed by this BD */
-	u32 status  :  8; /* E,R,I,C,W,D status bits stored here */
-	u32 command :  8; /* command mostly used for channel 0 */
-};
-
-/*
- * Buffer descriptor
- */
-struct sdma_buffer_descriptor {
-	struct sdma_mode_count  mode;
-	u32 buffer_addr;	/* address of the buffer described */
-	u32 ext_buffer_addr;	/* extended buffer address */
-} __attribute__ ((packed));
-
-/**
- * struct sdma_channel_control - Channel control Block
- *
- * @current_bd_ptr:	current buffer descriptor processed
- * @base_bd_ptr:	first element of buffer descriptor array
- * @unused:		padding. The SDMA engine expects an array of 128 byte
- *			control blocks
- */
-struct sdma_channel_control {
-	u32 current_bd_ptr;
-	u32 base_bd_ptr;
-	u32 unused[2];
-} __attribute__ ((packed));
-
-/**
- * struct sdma_state_registers - SDMA context for a channel
- *
- * @pc:		program counter
- * @unused1:	unused
- * @t:		test bit: status of arithmetic & test instruction
- * @rpc:	return program counter
- * @unused0:	unused
- * @sf:		source fault while loading data
- * @spc:	loop start program counter
- * @unused2:	unused
- * @df:		destination fault while storing data
- * @epc:	loop end program counter
- * @lm:		loop mode
- */
-struct sdma_state_registers {
-	u32 pc     :14;
-	u32 unused1: 1;
-	u32 t      : 1;
-	u32 rpc    :14;
-	u32 unused0: 1;
-	u32 sf     : 1;
-	u32 spc    :14;
-	u32 unused2: 1;
-	u32 df     : 1;
-	u32 epc    :14;
-	u32 lm     : 2;
-} __attribute__ ((packed));
-
-/**
- * struct sdma_context_data - sdma context specific to a channel
- *
- * @channel_state:	channel state bits
- * @gReg:		general registers
- * @mda:		burst dma destination address register
- * @msa:		burst dma source address register
- * @ms:			burst dma status register
- * @md:			burst dma data register
- * @pda:		peripheral dma destination address register
- * @psa:		peripheral dma source address register
- * @ps:			peripheral dma status register
- * @pd:			peripheral dma data register
- * @ca:			CRC polynomial register
- * @cs:			CRC accumulator register
- * @dda:		dedicated core destination address register
- * @dsa:		dedicated core source address register
- * @ds:			dedicated core status register
- * @dd:			dedicated core data register
- * @scratch0:		1st word of dedicated ram for context switch
- * @scratch1:		2nd word of dedicated ram for context switch
- * @scratch2:		3rd word of dedicated ram for context switch
- * @scratch3:		4th word of dedicated ram for context switch
- * @scratch4:		5th word of dedicated ram for context switch
- * @scratch5:		6th word of dedicated ram for context switch
- * @scratch6:		7th word of dedicated ram for context switch
- * @scratch7:		8th word of dedicated ram for context switch
- */
-struct sdma_context_data {
-	struct sdma_state_registers  channel_state;
-	u32  gReg[8];
-	u32  mda;
-	u32  msa;
-	u32  ms;
-	u32  md;
-	u32  pda;
-	u32  psa;
-	u32  ps;
-	u32  pd;
-	u32  ca;
-	u32  cs;
-	u32  dda;
-	u32  dsa;
-	u32  ds;
-	u32  dd;
-	u32  scratch0;
-	u32  scratch1;
-	u32  scratch2;
-	u32  scratch3;
-	u32  scratch4;
-	u32  scratch5;
-	u32  scratch6;
-	u32  scratch7;
-} __attribute__ ((packed));
-
-
-struct sdma_engine;
-
-/**
- * struct sdma_desc - descriptor structor for one transfer
- * @vd:			descriptor for virt dma
- * @num_bd:		number of descriptors currently handling
- * @bd_phys:		physical address of bd
- * @buf_tail:		ID of the buffer that was processed
- * @buf_ptail:		ID of the previous buffer that was processed
- * @period_len:		period length, used in cyclic.
- * @chn_real_count:	the real count updated from bd->mode.count
- * @chn_count:		the transfer count set
- * @sdmac:		sdma_channel pointer
- * @bd:			pointer of allocate bd
- */
 struct sdma_desc {
 	struct virt_dma_desc	vd;
 	unsigned int		num_bd;
@@ -399,9 +267,12 @@ struct sdma_channel {
 	unsigned int			fifo_num;
 	bool				sw_done;
 	u32				sw_done_sel;
+	struct dma_async_tx_descriptor 	cb;
+	struct tasklet_struct		cb_task;
 };
 
 #define IMX_DMA_SG_LOOP		BIT(0)
+#define IMX_DMA_CUSTOM_CALLBACK	BIT(1)
 
 #define MAX_DMA_CHANNELS 32
 #define MXC_SDMA_DEFAULT_PRIORITY 1
@@ -501,6 +372,8 @@ static int sdma_get_firmware(struct sdma_engine *sdma,
 static int sdma_get_firmware_wait(struct sdma_engine *sdma,
 		const char *fw_name);
 
+static struct sdma_engine *sdma_singleton = NULL;
+
 static struct sdma_driver_data sdma_imx31 = {
 	.chnenbl0 = SDMA_CHNENBL0_IMX31,
 	.num_events = 32,
@@ -713,13 +586,23 @@ MODULE_DEVICE_TABLE(of, sdma_dt_ids);
 #define SDMA_H_CONFIG_ACR	BIT(4)  /* indicates if AHB freq /core freq = 2 or 1 */
 #define SDMA_H_CONFIG_CSM	(3)       /* indicates which context switch mode is selected*/
 
+static void sdma_start_desc(struct sdma_channel *sdmac);
+
+/* returns an address in data space (32-bit words) */
+u32 sdma_channel_context_base(int ch)
+{
+	return 2048 + (sizeof(struct sdma_context_data) / 4) * ch;
+}
+EXPORT_SYMBOL(sdma_channel_context_base);
+
+
 static inline u32 chnenbl_ofs(struct sdma_engine *sdma, unsigned int event)
 {
 	u32 chnenbl0 = sdma->drvdata->chnenbl0;
 	return chnenbl0 + event * 4;
 }
 
-static int sdma_config_ownership(struct sdma_channel *sdmac,
+int sdma_config_ownership(struct sdma_channel *sdmac,
 		bool event_override, bool mcu_override, bool dsp_override)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
@@ -754,6 +637,7 @@ static int sdma_config_ownership(struct sdma_channel *sdmac,
 
 	return 0;
 }
+EXPORT_SYMBOL(sdma_config_ownership);
 
 static void sdma_enable_channel(struct sdma_engine *sdma, int channel)
 {
@@ -785,7 +669,7 @@ static int sdma_run_channel0(struct sdma_engine *sdma)
 	return ret;
 }
 
-static int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
+int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
 		u32 address)
 {
 	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
@@ -823,8 +707,9 @@ static int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
 
 	return ret;
 }
+EXPORT_SYMBOL(sdma_load_script);
 
-static void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
+void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
 	int channel = sdmac->channel;
@@ -850,8 +735,21 @@ static void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event)
 	}
 
 }
+EXPORT_SYMBOL(sdma_event_enable);
 
-static void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
+void sdma_event_enable_by_channel_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask, unsigned int event)
+{
+	unsigned long val;
+	u32 chnenbl = chnenbl_ofs(sdma, event);
+
+	val = readl_relaxed(sdma->regs + chnenbl);
+	val |= channel_mask;
+	writel_relaxed(val, sdma->regs + chnenbl);
+}
+EXPORT_SYMBOL(sdma_event_enable_by_channel_mask);
+
+void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
 	int channel = sdmac->channel;
@@ -862,6 +760,19 @@ static void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event)
 	__clear_bit(channel, &val);
 	writel_relaxed(val, sdma->regs + chnenbl);
 }
+EXPORT_SYMBOL(sdma_event_disable);
+
+void sdma_event_disable_by_channel_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask, unsigned int event)
+{
+	unsigned long val;
+	u32 chnenbl = chnenbl_ofs(sdma, event);
+
+	val = readl_relaxed(sdma->regs + chnenbl);
+	val &= ~channel_mask;
+	writel_relaxed(val, sdma->regs + chnenbl);
+}
+EXPORT_SYMBOL(sdma_event_disable_by_channel_mask);
 
 static struct sdma_desc *to_sdma_desc(struct dma_async_tx_descriptor *t)
 {
@@ -892,6 +803,119 @@ static void sdma_start_desc(struct sdma_channel *sdmac)
 	sdma_enable_channel(sdma, sdmac->channel);
 }
 
+int sdma_write_datamem(struct sdma_engine *sdma, void *buf, int size,
+		u32 address)
+{
+	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
+	void *buf_virt;
+	dma_addr_t buf_phys;
+	int ret;
+	unsigned long flags;
+	bool use_iram = true;
+
+	if (sdma->iram_pool) {
+		buf_virt = gen_pool_dma_alloc(sdma->iram_pool, size, &buf_phys);
+	} else {
+		buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+					      GFP_KERNEL);
+			use_iram = false;
+	}
+	if (!buf_virt) {
+		use_iram = false;
+		buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+				GFP_KERNEL);
+		if (!buf_virt)
+			return -ENOMEM;
+	}
+
+	spin_lock_irqsave(&sdma->channel_0_lock, flags);
+
+	bd0->mode.command = C0_SETDM;
+	bd0->mode.status = BD_DONE | BD_INTR | BD_WRAP | BD_EXTD;
+	bd0->mode.count = size / 4;
+	bd0->buffer_addr = buf_phys;
+	bd0->ext_buffer_addr = address;
+
+	memcpy(buf_virt, buf, size);
+
+	ret = sdma_run_channel0(sdma);
+
+	spin_unlock_irqrestore(&sdma->channel_0_lock, flags);
+
+	if (use_iram)
+		gen_pool_free(sdma->iram_pool, (unsigned long)buf_virt,
+				size);
+	else
+		dma_free_coherent(sdma->dev, size, buf_virt, buf_phys);
+
+	return ret;
+}
+EXPORT_SYMBOL(sdma_write_datamem);
+
+int sdma_fetch_datamem(struct sdma_engine *sdma, void *buf, int size,
+		u32 address)
+{
+	struct sdma_buffer_descriptor *bd0 = sdma->bd0;
+	void *buf_virt;
+	dma_addr_t buf_phys;
+	int ret;
+	unsigned long flags;
+	bool use_iram = true;
+
+	if (sdma->iram_pool) {
+		buf_virt = gen_pool_dma_alloc(sdma->iram_pool, size, &buf_phys);
+	} else {
+		buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+					      GFP_KERNEL);
+			use_iram = false;
+	}
+	if (!buf_virt) {
+		use_iram = false;
+		buf_virt = dma_alloc_coherent(sdma->dev, size, &buf_phys,
+				GFP_KERNEL);
+		if (!buf_virt)
+			return -ENOMEM;
+	}
+	spin_lock_irqsave(&sdma->channel_0_lock, flags);
+
+	bd0->mode.command = C0_GETDM;
+	bd0->mode.status = BD_DONE | BD_INTR | BD_WRAP | BD_EXTD;
+	bd0->mode.count = size / 4;
+	bd0->buffer_addr = buf_phys;
+	bd0->ext_buffer_addr = address;
+
+	ret = sdma_run_channel0(sdma);
+
+	memcpy(buf, buf_virt, size);
+
+	spin_unlock_irqrestore(&sdma->channel_0_lock, flags);
+
+	if (use_iram)
+		gen_pool_free(sdma->iram_pool, (unsigned long)buf_virt,
+				size);
+	else
+		dma_free_coherent(sdma->dev, size, buf_virt, buf_phys);
+
+	return ret;
+}
+EXPORT_SYMBOL(sdma_fetch_datamem);
+
+int sdma_fetch_partial_context(struct sdma_channel *sdmac, void *buf,
+	u32 byte_offset, u32 num_bytes)
+{
+	static const u32 csz = sizeof(struct sdma_context_data);
+	u32 addr;
+	if (num_bytes > csz || num_bytes == 0 ||
+	byte_offset >= csz || byte_offset+num_bytes > csz ||
+	num_bytes % sizeof(u32) || byte_offset % sizeof(u32)) {
+		dev_err(sdmac->sdma->dev, "%s: invalid offset/length", __func__);
+		return -EINVAL;
+	}
+	addr = sdma_channel_context_base(sdmac->channel) + byte_offset/sizeof(u32);
+	return sdma_fetch_datamem(sdmac->sdma, buf, num_bytes, addr);
+}
+EXPORT_SYMBOL(sdma_fetch_partial_context);
+
 static void sdma_update_channel_loop(struct sdma_channel *sdmac)
 {
 	struct sdma_buffer_descriptor *bd;
@@ -967,6 +991,14 @@ static void mxc_sdma_handle_channel_normal(struct sdma_channel *data)
 		sdmac->status = DMA_COMPLETE;
 }
 
+static void sdma_custom_callback_tasklet(unsigned long data)
+{
+	struct sdma_channel *sdmac = (struct sdma_channel *) data;
+
+	if (sdmac->cb.callback)
+		sdmac->cb.callback(sdmac->cb.callback_param);
+}
+
 static irqreturn_t sdma_int_handler(int irq, void *dev_id)
 {
 	struct sdma_engine *sdma = dev_id;
@@ -987,7 +1019,9 @@ static irqreturn_t sdma_int_handler(int irq, void *dev_id)
 
 		spin_lock(&sdmac->vc.lock);
 		desc = sdmac->desc;
-		if (desc) {
+		if (sdmac->flags & IMX_DMA_CUSTOM_CALLBACK && sdmac->cb.callback) {
+			tasklet_schedule(&sdmac->cb_task);
+		} else if (desc) {
 			if (sdmac->flags & IMX_DMA_SG_LOOP) {
 				if (sdmac->peripheral_type != IMX_DMATYPE_HDMI)
 					sdma_update_channel_loop(sdmac);
@@ -1212,6 +1246,23 @@ static struct sdma_channel *to_sdma_chan(struct dma_chan *chan)
 	return container_of(chan, struct sdma_channel, vc.chan);
 }
 
+int sdma_load_partial_context(struct sdma_channel *sdmac,
+	struct sdma_context_data *context, u32 byte_offset, u32 num_bytes)
+{
+	static const u32 csz = sizeof(*context);
+	u32 addr;
+	if (num_bytes > csz || num_bytes == 0 ||
+	byte_offset >= csz || byte_offset+num_bytes > csz ||
+	num_bytes % sizeof(u32) || byte_offset % sizeof(u32)) {
+		dev_err(sdmac->sdma->dev, "%s: invalid offset/length", __func__);
+		return -EINVAL;
+	}
+	addr = sdma_channel_context_base(sdmac->channel) + byte_offset/sizeof(u32);
+	return sdma_write_datamem(sdmac->sdma, context, num_bytes, addr);
+}
+EXPORT_SYMBOL(sdma_load_partial_context);
+
+
 static int sdma_disable_channel(struct dma_chan *chan)
 {
 	struct sdma_channel *sdmac = to_sdma_chan(chan);
@@ -1390,7 +1441,7 @@ static int sdma_config_channel(struct dma_chan *chan)
 	return 0;
 }
 
-static int sdma_set_channel_priority(struct sdma_channel *sdmac,
+int sdma_set_channel_priority(struct sdma_channel *sdmac,
 		unsigned int priority)
 {
 	struct sdma_engine *sdma = sdmac->sdma;
@@ -1405,6 +1456,25 @@ static int sdma_set_channel_priority(struct sdma_channel *sdmac,
 
 	return 0;
 }
+EXPORT_SYMBOL(sdma_set_channel_priority);
+
+void sdma_set_channel_pending(struct sdma_channel *sdmac)
+{
+	struct sdma_engine *sdma = sdmac->sdma;
+	int channel = sdmac->channel;
+	unsigned long val = 0;
+
+	__set_bit(channel, &val);
+	writel_relaxed(val, sdma->regs + SDMA_H_EVTPEND);
+}
+EXPORT_SYMBOL(sdma_set_channel_pending);
+
+void sdma_set_channel_pending_by_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask)
+{
+	writel_relaxed(channel_mask, sdma->regs + SDMA_H_EVTPEND);
+}
+EXPORT_SYMBOL(sdma_set_channel_pending_by_mask);
 
 static int sdma_request_channel0(struct sdma_engine *sdma)
 {
@@ -1465,6 +1535,23 @@ static void sdma_free_bd(struct sdma_desc *desc)
 				  desc->bd_phys);
 }
 
+void sdma_set_channel_interrupt_callback(struct sdma_channel *sdmac,
+		dma_async_tx_callback int_cb, void *cb_param)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&sdmac->vc.lock, flags);
+	if (int_cb)
+		sdmac->flags |= IMX_DMA_CUSTOM_CALLBACK;
+	else
+		sdmac->flags &= ~IMX_DMA_CUSTOM_CALLBACK;
+	sdmac->cb.callback = int_cb;
+	sdmac->cb.callback_param = cb_param;
+	tasklet_init(&sdmac->cb_task, sdma_custom_callback_tasklet,
+					 (unsigned long) sdmac);
+	spin_unlock_irqrestore(&sdmac->vc.lock, flags);
+}
+EXPORT_SYMBOL(sdma_set_channel_interrupt_callback);
+
 static void sdma_desc_free(struct virt_dma_desc *vd)
 {
 	struct sdma_desc *desc = container_of(vd, struct sdma_desc, vd);
@@ -2467,6 +2554,7 @@ static int sdma_probe(struct platform_device *pdev)
 	if (!sdma->drvdata->pm_runtime)
 		pm_runtime_get_sync(&pdev->dev);
 
+	sdma_singleton = sdma;
 	return 0;
 
 err_register:
@@ -2618,6 +2706,93 @@ static int sdma_resume(struct device *dev)
 }
 #endif
 
+struct sdma_channel *sdma_get_channel(struct sdma_engine *sdma, int channel)
+{
+	if (channel < 0 || channel >= MAX_DMA_CHANNELS) {
+		return NULL;
+	}
+	return &sdma->channel[channel];
+}
+EXPORT_SYMBOL(sdma_get_channel);
+
+/* (mjs) convenience function for initializing a channel as
+ * host-triggered or event-triggered
+ * external=false: channel started by host, HO[i]=0, EO[i]=1
+ * external=true: channel started by event, HO[i]=1, EO[i]=0 */
+void sdma_setup_channel(struct sdma_channel *sdmac, bool external)
+{
+	sdma_disable_channel(&sdmac->vc.chan);
+	sdma_config_ownership(sdmac,
+		external,   /* event override */
+		!external,  /* host override */
+		false);     /* always false */
+}
+EXPORT_SYMBOL(sdma_setup_channel);
+
+struct sdma_engine *sdma_engine_get(void)
+{
+	return sdma_singleton;
+}
+EXPORT_SYMBOL(sdma_engine_get);
+
+ssize_t sdma_print_context(struct sdma_engine *sdma, int channel, char *buf)
+{
+	static const char *regnames[] = {
+		" r0", " r1", " r2", " r3", " r4", " r5", " r6", " r7",
+		"mda", "msa", " ms", " md", "pda", "psa", " ps", " pd",
+		" ca", " cs", "dda", "dsa", " ds", " dd", "sc0", "sc1",
+		"sc2", "sc3", "sc4", "sc5", "sc6", "sc7"
+	};
+
+	struct sdma_context_data *context;
+	u32 context_addr = sdma_channel_context_base(channel);
+	u32 context_size = sizeof(*context);
+	u32 *regptr;
+	int ret;
+	int i;
+	ssize_t outlen = 0;
+
+	context = kzalloc(context_size, GFP_ATOMIC);
+	if (!context) {
+		return -ENOMEM;
+	}
+
+	ret = sdma_fetch_datamem(sdma, context, context_size, context_addr);
+	if (ret) {
+		return ret;
+	}
+
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+		"pc=%04x rpc=%04x spc=%04x epc=%04x\n",
+		context->channel_state.pc,
+		context->channel_state.rpc,
+		context->channel_state.spc,
+		context->channel_state.epc
+	);
+
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+		"Flags: t=%d sf=%d df=%d lm=%d\n",
+		(context->channel_state.t != 0),
+		(context->channel_state.sf != 0),
+		(context->channel_state.df != 0),
+		(context->channel_state.lm != 0)
+	);
+
+	regptr = &context->gReg[0];
+	for (i = 0; i < ARRAY_SIZE(regnames); i++) {
+		outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen,
+			"%s=%08x%c",
+			regnames[i],
+			regptr[i],
+			((i % 6) == 5) ? '\n' : ' ');
+	}
+	outlen += scnprintf(buf+outlen, PAGE_SIZE-outlen, "\n");
+
+	kfree(context);
+	return outlen;
+}
+EXPORT_SYMBOL(sdma_print_context);
+
 static const struct dev_pm_ops sdma_pm_ops = {
 	SET_LATE_SYSTEM_SLEEP_PM_OPS(sdma_suspend, sdma_resume)
 	SET_RUNTIME_PM_OPS(sdma_runtime_suspend, sdma_runtime_resume, NULL)
diff --git a/include/linux/platform_data/dma-imx-sdma.h b/include/linux/platform_data/dma-imx-sdma.h
index e12d2e8c246b..1510b643c494 100644
--- a/include/linux/platform_data/dma-imx-sdma.h
+++ b/include/linux/platform_data/dma-imx-sdma.h
@@ -1,7 +1,8 @@
-/* SPDX-License-Identifier: GPL-2.0 */
 #ifndef __MACH_MXC_SDMA_H__
 #define __MACH_MXC_SDMA_H__
 
+#include <linux/dmaengine.h>
+
 /**
  * struct sdma_script_start_addrs - SDMA script start pointers
  *
@@ -72,4 +73,320 @@ struct sdma_platform_data {
 	struct sdma_script_start_addrs *script_addrs;
 };
 
+/*
+ * Mode/Count of data node descriptors - IPCv2
+ */
+struct sdma_mode_count {
+	u32 count   : 16; /* size of the buffer pointed by this BD */
+	u32 status  :  8; /* E,R,I,C,W,D status bits stored here */
+	u32 command :  8; /* command mostlky used for channel 0 */
+};
+
+/*
+ * Buffer descriptor
+ */
+struct sdma_buffer_descriptor {
+	struct sdma_mode_count  mode;
+	u32 buffer_addr;	/* address of the buffer described */
+	u32 ext_buffer_addr;	/* extended buffer address */
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_channel_control - Channel control Block
+ *
+ * @current_bd_ptr	current buffer descriptor processed
+ * @base_bd_ptr		first element of buffer descriptor array
+ * @unused		padding. The SDMA engine expects an array of 128 byte
+ *			control blocks
+ */
+struct sdma_channel_control {
+	u32 current_bd_ptr;
+	u32 base_bd_ptr;
+	u32 unused[2];
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_state_registers - SDMA context for a channel
+ *
+ * @pc:		program counter
+ * @t:		test bit: status of arithmetic & test instruction
+ * @rpc:	return program counter
+ * @sf:		source fault while loading data
+ * @spc:	loop start program counter
+ * @df:		destination fault while storing data
+ * @epc:	loop end program counter
+ * @lm:		loop mode
+ */
+struct sdma_state_registers {
+	u32 pc     :14;
+	u32 unused1: 1;
+	u32 t      : 1;
+	u32 rpc    :14;
+	u32 unused0: 1;
+	u32 sf     : 1;
+	u32 spc    :14;
+	u32 unused2: 1;
+	u32 df     : 1;
+	u32 epc    :14;
+	u32 lm     : 2;
+} __attribute__ ((packed));
+
+/**
+ * struct sdma_context_data - sdma context specific to a channel
+ *
+ * @channel_state:	channel state bits
+ * @gReg:		general registers
+ * @mda:		burst dma destination address register
+ * @msa:		burst dma source address register
+ * @ms:			burst dma status register
+ * @md:			burst dma data register
+ * @pda:		peripheral dma destination address register
+ * @psa:		peripheral dma source address register
+ * @ps:			peripheral dma status register
+ * @pd:			peripheral dma data register
+ * @ca:			CRC polynomial register
+ * @cs:			CRC accumulator register
+ * @dda:		dedicated core destination address register
+ * @dsa:		dedicated core source address register
+ * @ds:			dedicated core status register
+ * @dd:			dedicated core data register
+ */
+struct sdma_context_data {
+	struct sdma_state_registers  channel_state;
+	u32  gReg[8];
+	u32  mda;
+	u32  msa;
+	u32  ms;
+	u32  md;
+	u32  pda;
+	u32  psa;
+	u32  ps;
+	u32  pd;
+	u32  ca;
+	u32  cs;
+	u32  dda;
+	u32  dsa;
+	u32  ds;
+	u32  dd;
+	u32  scratch0;
+	u32  scratch1;
+	u32  scratch2;
+	u32  scratch3;
+	u32  scratch4;
+	u32  scratch5;
+	u32  scratch6;
+	u32  scratch7;
+} __attribute__ ((packed));
+
+#define NUM_BD (int)(PAGE_SIZE / sizeof(struct sdma_buffer_descriptor))
+#define SDMA_BD_MAX_CNT	0xfffc /* align with 4 bytes */
+
+struct sdma_engine;
+
+struct sdma_channel;
+
+/**
+ * sdma_engine_get() - returns a pointer to the global SDMA engine
+ *
+ * Return: pointer to the sdma_engine object
+ */
+struct sdma_engine *sdma_engine_get(void);
+
+/**
+ * sdma_get_channel() - returns a pointer to the numbered SDMA channel
+ * @sdma:	pointer to the sdma_engine object
+ * @channel:	channel number from 0-31
+ *
+ * Return: pointer to channel object, or NULL
+ */
+struct sdma_channel *sdma_get_channel(struct sdma_engine *sdma, int channel);
+
+/**
+ * sdma_set_channel_interrupt_callback() - sets a custom interrupt handler
+ * @sdmac:	pointer to sdma_channel object
+ * @int_cb:	callback function to register
+ * @cb_param:	user-defined object passed when the callback is invoked
+ *
+ * Sets a function to be called when a custom SDMA script triggers an interrupt
+ * (e.g. with a "done 3" instruction).
+ * The function is executed in tasklet (atomic) context.
+ */
+void sdma_set_channel_interrupt_callback(struct sdma_channel *sdmac,
+		dma_async_tx_callback int_cb, void *cb_param);
+
+/**
+ * sdma_set_channel_priority() - sets the channel's execution priority
+ * @sdmac:	pointer to sdma_channel object
+ * @priority:	priority, from 0 (disabled) to 7 (highest)
+ *
+ * Setting a nonzero priority may cause the channel's script to begin executing,
+ * depending on how it is configured.
+ * Priority 7 is used by channel 0 for loading scripts/context. Typically,
+ * channel 0 should be the only channel with priority 7.
+ *
+ * Return: 0 on success, nonzero otherwise
+ */
+int sdma_set_channel_priority(struct sdma_channel *sdmac,
+		unsigned int priority);
+
+/**
+ * sdma_set_channel_pending() - sets the channel as pending
+ * @sdmac:	pointer to sdma_channel object
+ */
+void sdma_set_channel_pending(struct sdma_channel *sdmac);
+
+/**
+ * sdma_set_channel_pending_by_channel_mask() - sets a group of channels as
+ * pending
+ * @sdma:	pointer to the sdma_engine object
+ * @channel_mask: bitmask of channels to set pending
+ */
+void sdma_set_channel_pending_by_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask);
+
+/**
+ * sdma_setup_channel() - convenience function for setting channel ownership
+ * @sdmac:	pointer to sdma_channel object
+ * @external:	if true, script is triggered by an external event,
+ *		if false, script is triggered by the CPU
+ */
+void sdma_setup_channel(struct sdma_channel *sdmac, bool external);
+
+/**
+ * sdma_event_enable() - allows a channel to be triggered by the numbered event
+ * @sdmac:	pointer to sdma_channel object
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_enable(struct sdma_channel *sdmac, unsigned int event);
+
+/**
+ * sdma_event_enable_by_channel_mask() - allows a group of channels to be
+ * triggered by the numbered event
+ * @sdma:	pointer to the sdma_engine object
+ * @channel_mask: bitmask of channels to enable
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_enable_by_channel_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask, unsigned int event);
+
+/**
+ * sdma_event_disable() - prevents a channel from being triggered by an event
+ * @sdmac:	pointer to sdma_channel object
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_disable(struct sdma_channel *sdmac, unsigned int event);
+
+/**
+ * sdma_event_disable_by_channel_mask() - prevents a group of channels from
+ * being triggered by an event
+ * @sdma:	pointer to the sdma_engine object
+ * @channel_mask: bitmask of channels to disable
+ * @event:	event number (see reference manual)
+ */
+void sdma_event_disable_by_channel_mask(struct sdma_engine *sdma,
+	unsigned int channel_mask, unsigned int event);
+
+/**
+ * sdma_is_event_enabled() - returns whether an event can trigger the channel
+ * @sdmac:	pointer to sdma_channel object
+ * @event:	event number (see reference manual)
+ * Return: 0 if disabled, nonzero if enabled
+ */
+int sdma_is_event_enabled(struct sdma_channel *sdmac, unsigned int event);
+
+/* address should be in program space (halfword addressing) */
+
+/**
+ * sdma_load_script() - copies script from ARM memory to SDMA memory
+ * @sdma:	pointer to sdma_engine object
+ * @buf:	start of script
+ * @size:	size of script in bytes
+ * @address:	destination address in SDMA program space
+ *		(using halfword addressing)
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_load_script(struct sdma_engine *sdma, void *buf, int size,
+		u32 address);
+
+/**
+ * sdma_load_partial_context() - writes a subset of a channel's context
+ * @sdmac:		pointer to sdma_channel object
+ * @context:		pointer to data to write
+ * @byte_offset:	destination offset within the channel's context RAM
+ *			(must be a multiple of 4 and less than 128)
+ * @num_bytes:		number of bytes to copy into the channel's context RAM
+ *			(must be > 0 and <= 128)
+ *
+ * Can be used to update a subset of a channel's registers while leaving others
+ * undisturbed, e.g. to change a script's arguments while it is running without
+ * overwriting internal state.
+ * Since RAM loading is handled by channel 0, and channels cannot preempt each
+ * other, the load operation is mutually exclusive with the channel's execution.
+ * (i.e. a channel's registers will not change while its script is executing.)
+ *
+ * Example: to update a channel's entire context, use byte_offset=0 and
+ * num_bytes=128.
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_load_partial_context(struct sdma_channel *sdmac,
+	struct sdma_context_data *context,
+	u32 byte_offset,
+	u32 num_bytes);
+
+/* size should be a value in bytes */
+/* address should be in data space (word addressing) */
+
+/**
+ * sdma_write_datamem() - writes data into the SDMA engine's address space
+ * @sdma:	pointer to sdma_engine object
+ * @buf:	data to write
+ * @size:	number of bytes to write
+ * @address:	destination offset, in 32-bit words, from the origin of SDMA
+ *		address space
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_write_datamem(struct sdma_engine *sdma, void *buf, int size,
+	u32 address);
+
+/**
+ * sdma_fetch_partial_context() - reads a subset of a channel's context
+ * @sdmac:		pointer to sdma_channel object
+ * @buf:		buffer to receive data
+ * @byte_offset:	source offset within the channel's context RAM
+ *			(must be a multiple of 4 and less than 128)
+ * @num_bytes:		number of bytes to read from the channel's context RAM
+ *			(must be > 0 and <= 128)
+ *
+ * Since RAM loading is handled by channel 0, and channels cannot preempt each
+ * other, the fetch operation is mutually exclusive with the channel's
+ * execution. (i.e. the values will not be changing at the same time as they are
+ * being read.)
+ *
+ * Example: to fetch a channel's entire context, use byte_offset=0 and
+ * num_bytes=128.
+ *
+ * buf must be large enough to hold num_bytes of data.
+ *
+ * Return: 0 on success, nonzero on error
+ */
+int sdma_fetch_partial_context(struct sdma_channel *sdmac, void *buf,
+    u32 byte_offset,
+    u32 num_bytes);
+
+/**
+ * sdma_print_context() - dump string representation of channel context values
+ * @sdma:	pointer to sdma_engine object
+ * @channel:	channel number, 0-31
+ * @buf:	buffer to receive the string
+ *
+ * Prints a string representation of all channel registers and scratch memory
+ * words. buf should be at least 512 bytes long. Useful for debugging.
+ *
+ * Return: result string length in bytes, or < 0 on error
+ */
+ssize_t sdma_print_context(struct sdma_engine *sdma, int channel, char *buf);
+
 #endif /* __MACH_MXC_SDMA_H__ */
diff --git a/include/linux/platform_data/epit-imx.h b/include/linux/platform_data/epit-imx.h
new file mode 100644
index 000000000000..c4efdc694c7b
--- /dev/null
+++ b/include/linux/platform_data/epit-imx.h
@@ -0,0 +1,141 @@
+/**
+ * Low-level i.MX6 EPIT API.
+ * Copyright (C) 2015-2018 Glowforge, Inc. <opensource@glowforge.com>
+ *
+ * The i.MX6 has two EPIT (Enhanced Periodic Interrupt Timer) units, both of
+ * which are unused by the Linux kernel. This header exposes a low-level API
+ * for configuring an EPIT.
+ */
+
+#ifndef __MACH_MXC_EPIT_H__
+#define __MACH_MXC_EPIT_H__
+
+#include <linux/types.h>
+
+struct epit;
+struct device_node;
+
+typedef void (*epit_cb)(void *);
+
+/**
+ * epit_get() - returns a pointer to the EPIT for the given device_node
+ * @np:		device tree node for EPIT1 or EPIT2
+ *
+ * Return: pointer to epit object, or NULL
+ */
+struct epit *epit_get(struct device_node *np);
+
+/**
+ * epit_init_freerunning() - initializes EPIT in "set and forget" mode
+ * @epit:	pointer to epit object
+ * @callback:	function to execute periodically
+ * @cb_arg:	user-defined object passed when the callback is invoked
+ *
+ * The timer is started when epit_start() is called.
+ * If callback is non-NULL, it will be executed (in interrupt context) when the
+ * timer overflows.
+ *
+ * Return: 0 on success, nonzero otherwise
+ */
+int epit_init_freerunning(struct epit *epit, epit_cb callback, void *cb_arg);
+
+/**
+ * epit_init_oneshot() - initializes EPIT for retriggerable one-shot timeouts
+ * @epit:	pointer to epit object
+ * @callback:	function to execute periodically
+ * @cb_arg:	user-defined object passed when the callback is invoked
+ *
+ * The timer is started when epit_start() is called, and the callback is
+ * executed with the given argument (in interupt context) if the timeout is
+ * reached.
+ */
+int epit_init_oneshot(struct epit *epit, epit_cb callback, void *cb_arg);
+
+/**
+ * epit_hz_to_divisor() - converts frequency in hertz to a clock divider value
+ * @epit:	pointer to epit object
+ * @hz:		frequency in Hz
+ *
+ * Return: divisor value for the desired frequency
+ */
+u32 epit_hz_to_divisor(struct epit *epit, u32 hz);
+
+/**
+ * epit_start() - starts an EPIT with the given period
+ * @epit:	pointer to epit object
+ * @divisor:	length of timer interval in ticks
+ */
+void epit_start(struct epit *epit, u32 divisor);
+
+/**
+ * epit_start_hz() - starts a free-running EPIT with the given frequency
+ * @epit:	pointer to epit object
+ * @hz:		frequency in Hz
+ */
+void epit_start_hz(struct epit *epit, u32 hz);
+
+/**
+ * epit_stop() - stops an EPIT
+ * @epit:	pointer to epit object
+ */
+void epit_stop(struct epit *epit);
+
+/**
+ * epit_set_divisor() - change an EPIT's period
+ * @epit:	pointer to epit object
+ * @divisor:	new length of timer interval in ticks
+ *
+ * Takes effect the next time epit_start() is called.
+ */
+void epit_set_divisor(struct epit *epit, u32 divisor);
+
+/**
+ * epit_set_hz() - change an EPIT's frequency
+ * @epit:	pointer to epit object
+ * @hz:		new frequency in Hz
+ *
+ * Takes effect the next time epit_start() is called.
+ */
+void epit_set_hz(struct epit *epit, u32 hz);
+
+/**
+ * epit_count() - returns the EPIT's current count
+ * @epit:	pointer to epit object
+ *
+ * Return: current value of the EPIT's counter
+ */
+u32 epit_count(struct epit *epit);
+
+/**
+ * epit_is_running() - returns whether or not an EPIT is running
+ * @epit:	pointer to epit object
+ *
+ * Return: 1 if timer is running, 0 otherwise
+ */
+int epit_is_running(struct epit *epit);
+
+/**
+ * epit_irq() - returns the EPIT's IRQ number
+ * @epit:	pointer to epit object
+ *
+ * Return: the EPIT's IRQ number
+ */
+int epit_irq(struct epit *epit);
+
+/**
+ * epit_sdma_event() - returns the EPIT's SDMA event number
+ * @epit:	pointer to epit object
+ *
+ * Return: the EPIT's SDMA event number
+ */
+int epit_sdma_event(struct epit *epit);
+
+/**
+ * epit_status_register_address() - returns physical address of status register
+ * @epit:	pointer to epit object
+ *
+ * Return: the physical address of the EPIT's EPITSR register
+ */
+u32 epit_status_register_address(struct epit *epit);
+
+#endif
-- 
2.32.0

